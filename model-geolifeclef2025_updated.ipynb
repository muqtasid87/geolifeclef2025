{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794eea60",
   "metadata": {},
   "source": [
    "# GeoLifeCLEF 2025 Model Notebook\n",
    "\n",
    "This notebook provides a comprehensive example of how to approach the GeoLifeCLEF 2025 competition. It covers data acquisition, preprocessing, model training, and submission generation. Each section is thoroughly commented and includes descriptive headers to facilitate understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d96ddb",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Acquisition\n",
    "\n",
    "The necessary libraries (e.g., PyTorch, pandas, rasterio) are installed, and the GeoLifeCLEF 2025 dataset is downloaded from Kaggle using the Kaggle API. Authentication with Kaggle is required; ensure your API token is configured correctly. The dataset includes training and testing metadata (GLC25_PA_metadata_train.csv, GLC25_PA_metadata_test.csv) and environmental rasters (Landsat, Bioclim, Sentinel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de872f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.1.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.11/site-packages (from rasterio) (24.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from rasterio) (2024.8.30)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.11/site-packages (from rasterio) (8.1.7)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing (from rasterio)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.10.0 (from albumentations)\n",
      "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from albumentations) (6.0.2)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.4.9-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (66 kB)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.11/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: charset-normalizer in /opt/conda/lib/python3.11/site-packages (from kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from kaggle) (3.10)\n",
      "Collecting protobuf (from kaggle)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.11/site-packages (from kaggle) (72.1.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.11/site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from kagglehub) (24.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: pillow>=10.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (10.2.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2025.6.1-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m165.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2025.6.1-py3-none-any.whl (230 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading simsimd-6.4.9-cp311-cp311-manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: text-unidecode, stringzilla, simsimd, tzdata, typing-inspection, tifffile, threadpoolctl, scipy, python-slugify, pyparsing, pydantic-core, protobuf, opencv-python-headless, lazy-loader, kiwisolver, joblib, imageio, fonttools, cycler, contourpy, cligj, click-plugins, annotated-types, affine, scikit-learn, scikit-image, rasterio, pydantic, pandas, matplotlib, kagglehub, kaggle, albucore, seaborn, albumentations\n",
      "Successfully installed affine-2.4.0 albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 click-plugins-1.1.1 cligj-0.7.2 contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.2 imageio-2.37.0 joblib-1.5.1 kaggle-1.7.4.5 kagglehub-0.3.12 kiwisolver-1.4.8 lazy-loader-0.4 matplotlib-3.10.3 opencv-python-headless-4.11.0.86 pandas-2.3.0 protobuf-6.31.1 pydantic-2.11.5 pydantic-core-2.33.2 pyparsing-3.2.3 python-slugify-8.0.4 rasterio-1.4.3 scikit-image-0.25.2 scikit-learn-1.7.0 scipy-1.15.3 seaborn-0.13.2 simsimd-6.4.9 stringzilla-3.12.5 text-unidecode-1.3 threadpoolctl-3.6.0 tifffile-2025.6.1 typing-inspection-0.4.1 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rasterio tqdm numpy pandas albumentations kaggle kagglehub scikit-learn scikit-image matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3a32c",
   "metadata": {},
   "source": [
    "### 1.1 Kaggle Authentication\n",
    "\n",
    "Authenticates with Kaggle to allow programmatic access to datasets and competitions. Ensure your Kaggle API token is configured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ad1ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11856834c970492e96b941587099871b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b440a41",
   "metadata": {},
   "source": [
    "### 1.2 Download Competition Data\n",
    "\n",
    "Downloads the GeoLifeCLEF 2025 competition dataset. This may take some time due to the size of the dataset, as it includes various environmental rasters and observation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d168b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/geolifeclef-2025...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.73G/3.73G [01:47<00:00, 37.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "geolifeclef_2025_path = kagglehub.competition_download('geolifeclef-2025')\n",
    "\n",
    "print('Data source import complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b489ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18570e4b",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration\n",
    "\n",
    "This section focuses on loading the downloaded data, including observations and environmental rasters, and performing initial data exploration to understand its structure and content. We will load `observations.csv` for both training and testing, and `train_labels.csv` for the training target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c7ab1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torchmetrics import F1Score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(f\"{geolifeclef_2025_path}/GLC25_PA_metadata_train.csv\")\n",
    "test_metadata = pd.read_csv(f\"{geolifeclef_2025_path}/GLC25_PA_metadata_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b91c09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5016\n",
      "3425\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(train_metadata.speciesId.values, return_counts=True)\n",
    "print(len(unique))\n",
    "\n",
    "new_unique, new_counts = [], []\n",
    "for u, c in zip(unique, counts):\n",
    "    if c > 5:\n",
    "        new_unique.append(u)\n",
    "        new_counts.append(c)\n",
    "unique = np.array(new_unique)\n",
    "counts = np.array(new_counts)\n",
    "print(len(unique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6654a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(unique)\n",
    "num_surveys = len(np.unique(train_metadata.surveyId.values))\n",
    "\n",
    "species_dict = {}\n",
    "for i in range(num_classes):\n",
    "    species_dict[unique[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c34057",
   "metadata": {},
   "source": [
    "# Dataset, Data preprocessing, and data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cebd2d",
   "metadata": {},
   "source": [
    "The training and testing metadata are loaded from CSV files. The training metadata contains species IDs and survey IDs. Initial exploration reveals 5016 unique species, but only 3425 have more than 5 observations. The model focuses on these 3425 species, and a dictionary maps their IDs to indices for use in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c86771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_patch_path(data_path, survey_id):\n",
    "    \"\"\"Construct the patch file path based on plot_id as './CD/AB/XXXXABCD.jpeg'\"\"\"\n",
    "    path = data_path\n",
    "    for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "        path = os.path.join(path, d)\n",
    "\n",
    "    path = os.path.join(path, f\"{survey_id}.tiff\")\n",
    "\n",
    "    return path\n",
    "\n",
    "def quantile_normalize(band, low=2, high=98):\n",
    "    sorted_band = np.sort(band.flatten())\n",
    "    quantiles = np.percentile(sorted_band, np.linspace(low, high, len(sorted_band)))\n",
    "    normalized_band = np.interp(band.flatten(), sorted_band, quantiles).reshape(band.shape)\n",
    "    \n",
    "    min_val, max_val = np.min(normalized_band), np.max(normalized_band)\n",
    "    \n",
    "    # Prevent division by zero if min_val == max_val\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(normalized_band, dtype=np.float32)  # Return an array of zeros\n",
    "\n",
    "    # Perform normalization (min-max scaling)\n",
    "    return ((normalized_band - min_val) / (max_val - min_val)).astype(np.float32)\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, bioclim_data_dir, landsat_data_dir, sentinel_data_dir, metadata, transform=None):\n",
    "        self.transform = transform\n",
    "        self.sentinel_transform = A.Compose([\n",
    "            A.Rotate(limit=(-10, 10)),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.05, 0.05), contrast_limit=(-0.05, 0.05), p=0.3),\n",
    "            A.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5, 0.5), max_pixel_value=1),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "      \n",
    "        self.bioclim_data_dir = bioclim_data_dir\n",
    "        self.landsat_data_dir = landsat_data_dir\n",
    "        self.sentinel_data_dir = sentinel_data_dir\n",
    "        self.metadata = metadata\n",
    "        self.metadata = self.metadata.dropna(subset=\"speciesId\").reset_index(drop=True)\n",
    "        self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)\n",
    "        self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "        \n",
    "        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        \n",
    "        landsat_sample = torch.nan_to_num(torch.load(os.path.join(self.landsat_data_dir, f\"GLC25-PA-train-landsat-time-series_{survey_id}_cube.pt\")))\n",
    "        bioclim_sample = torch.nan_to_num(torch.load(os.path.join(self.bioclim_data_dir, f\"GLC25-PA-train-bioclimatic_monthly_{survey_id}_cube.pt\")))\n",
    "        \n",
    "        \n",
    "        tiff_path = construct_patch_path(self.sentinel_data_dir, survey_id)\n",
    "        with rasterio.open(tiff_path) as dataset:\n",
    "            sentinel_sample = dataset.read(out_dtype=np.float32)  # Read all bands\n",
    "            sentinel_sample = np.array([quantile_normalize(band) for band in sentinel_sample])  # Apply quantile normalization\n",
    "        sentinel_sample = np.transpose(sentinel_sample, (1, 2, 0)) \n",
    "\n",
    "        species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n",
    "        label = torch.zeros(num_classes)  # Initialize label tensor\n",
    "        for species_id in species_ids:\n",
    "            label_id = species_id\n",
    "            if label_id in species_dict.keys():\n",
    "                label[species_dict[label_id]] = 1 # Set the corresponding class index to 1 for each species\n",
    "        \n",
    "        if isinstance(landsat_sample, torch.Tensor):\n",
    "            landsat_sample = landsat_sample.permute(1, 2, 0)  # Change tensor shape from (C, H, W) to (H, W, C)\n",
    "            landsat_sample = landsat_sample.numpy()  # Convert tensor to numpy array\n",
    "            \n",
    "        if isinstance(bioclim_sample, torch.Tensor):\n",
    "            bioclim_sample = bioclim_sample.permute(1, 2, 0)  # Change tensor shape from (C, H, W) to (H, W, C)\n",
    "            bioclim_sample = bioclim_sample.numpy()  # Convert tensor to numpy array   \n",
    "        \n",
    "        if self.transform:\n",
    "            landsat_sample = self.transform(landsat_sample)\n",
    "            bioclim_sample = self.transform(bioclim_sample)\n",
    "            sentinel_sample = self.sentinel_transform(image=sentinel_sample)['image']\n",
    "        \n",
    "        \n",
    "        return landsat_sample, bioclim_sample, sentinel_sample, label, survey_id\n",
    "    \n",
    "class TestDataset(TrainDataset):\n",
    "    def __init__(self, bioclim_data_dir, landsat_data_dir, sentinel_data_dir, metadata, transform=None):\n",
    "        self.transform = transform\n",
    "        self.sentinel_transform = A.Compose([\n",
    "            A.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5, 0.5), max_pixel_value=1),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "      \n",
    "        self.bioclim_data_dir = bioclim_data_dir\n",
    "        self.landsat_data_dir = landsat_data_dir\n",
    "        self.sentinel_data_dir = sentinel_data_dir\n",
    "        self.metadata = metadata\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        landsat_sample = torch.nan_to_num(torch.load(os.path.join(self.landsat_data_dir, f\"GLC25-PA-test-landsat_time_series_{survey_id}_cube.pt\")))\n",
    "        bioclim_sample = torch.nan_to_num(torch.load(os.path.join(self.bioclim_data_dir, f\"GLC25-PA-test-bioclimatic_monthly_{survey_id}_cube.pt\")))\n",
    "        \n",
    "        \n",
    "        tiff_path = construct_patch_path(self.sentinel_data_dir, survey_id)\n",
    "        with rasterio.open(tiff_path) as dataset:\n",
    "            sentinel_sample = dataset.read(out_dtype=np.float32)  # Read all bands\n",
    "            sentinel_sample = np.array([quantile_normalize(band) for band in sentinel_sample])  # Apply quantile normalization\n",
    "        sentinel_sample = np.transpose(sentinel_sample, (1, 2, 0)) \n",
    "            \n",
    "        if isinstance(landsat_sample, torch.Tensor):\n",
    "            landsat_sample = landsat_sample.permute(1, 2, 0)  # Change tensor shape from (C, H, W) to (H, W, C)\n",
    "            landsat_sample = landsat_sample.numpy()  # Convert tensor to numpy array\n",
    "        if isinstance(bioclim_sample, torch.Tensor):\n",
    "            bioclim_sample = bioclim_sample.permute(1, 2, 0)  # Change tensor shape from (C, H, W) to (H, W, C)\n",
    "            bioclim_sample = bioclim_sample.numpy()  # Convert tensor to numpy array   \n",
    "        \n",
    "        if self.transform:\n",
    "            landsat_sample = self.transform(landsat_sample)\n",
    "            bioclim_sample = self.transform(bioclim_sample)\n",
    "            sentinel_sample = self.sentinel_transform(image=sentinel_sample)['image']\n",
    "        \n",
    "        return landsat_sample, bioclim_sample, sentinel_sample, survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "batch_size = 256\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load Training metadata\n",
    "train_landsat_data_path = f\"{geolifeclef_2025_path}/SateliteTimeSeries-Landsat/cubes/PA-train/\"\n",
    "train_bioclim_data_path = f\"{geolifeclef_2025_path}/BioclimTimeSeries/cubes/PA-train/\"\n",
    "train_sentinel_data_path=f\"{geolifeclef_2025_path}/SatelitePatches/PA-train/\"\n",
    "train_metadata_path = f\"{geolifeclef_2025_path}/GLC25_PA_metadata_train.csv\"\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "dataset_alpine = TrainDataset(train_bioclim_data_path, train_landsat_data_path, train_sentinel_data_path, train_metadata, transform=transform)\n",
    "train_loader = DataLoader(dataset_alpine, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Load Test metadata\n",
    "test_landsat_data_path = f\"{geolifeclef_2025_path}/SateliteTimeSeries-Landsat/cubes/PA-test/\"\n",
    "test_bioclim_data_path = f\"{geolifeclef_2025_path}/BioclimTimeSeries/cubes/PA-test/\"\n",
    "test_sentinel_data_path = f\"{geolifeclef_2025_path}/SatelitePatches/PA-test/\"\n",
    "test_metadata_path = f\"{geolifeclef_2025_path}/GLC25_PA_metadata_test.csv\"\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "test_dataset = TestDataset(test_bioclim_data_path, test_landsat_data_path, test_sentinel_data_path, test_metadata, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f385f90",
   "metadata": {},
   "source": [
    "# Model Architeture Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ec5d4",
   "metadata": {},
   "source": [
    "The model is a multimodal ensemble combining three Swin Transformers:\n",
    "\n",
    "Landsat time series: Processed with a Swin Transformer (6 input channels).\n",
    "Bioclimatic monthly data: Processed with a Swin Transformer (4 input channels).\n",
    "Sentinel patches: Processed with a pre-trained Swin Transformer (4 input channels).\n",
    "Features from each transformer are projected to 1000 dimensions, concatenated, and passed through a classification head to predict the 3425 species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MultimodalEnsemble(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultimodalEnsemble, self).__init__()\n",
    "        \n",
    "        self.landsat_norm = nn.LayerNorm([6,4,21]) # Normalize Landsat data\n",
    "        self.landsat_model = models.swin_t(weights=None) # Initialize Swin Transformer model for Landsat data\n",
    "        self.landsat_model.features[0][0] = nn.Conv2d(6, 96, kernel_size=(4, 4), stride=(4, 4)) # Change input channels to 6\n",
    "        self.landsat_model.head = nn.Identity() # Remove the classification head\n",
    "        \n",
    "        self.bioclim_norm = nn.LayerNorm([4,19,12])# Normalize Bioclim data\n",
    "        self.bioclim_model = models.swin_t(weights=None)# Initialize Swin Transformer model for Bioclim data\n",
    "        self.bioclim_model.features[0][0] = nn.Conv2d(4, 96, kernel_size=(4, 4), stride=(4, 4))# Change input channels to 4\n",
    "        self.bioclim_model.head = nn.Identity()# Remove the classification head\n",
    "        \n",
    "        self.sentinel_model = models.swin_t(weights=\"IMAGENET1K_V1\")# Initialize Swin Transformer model for Sentinel data\n",
    "        self.sentinel_model.features[0][0] = nn.Conv2d(4, 96, kernel_size=(4, 4), stride=(4, 4))# Change input channels to 4\n",
    "        self.sentinel_model.head = nn.Identity() # Remove the classification head\n",
    "        \n",
    "        self.proj1 = nn.Sequential(# Project Landsat features\n",
    "            nn.Linear(768, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.proj2 = nn.Sequential(# Project Bioclim features\n",
    "            nn.Linear(768, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.proj3 = nn.Sequential(# Project Sentinel features\n",
    "            nn.Linear(768, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.label = nn.Sequential( # Final classification head\n",
    "            nn.Linear(3000, 4096),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(4096, num_classes),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(num_classes, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y, z): # x: Landsat data, y: Bioclim data, z: Sentinel data\n",
    "        \n",
    "        x = self.landsat_norm(x)\n",
    "        x = self.landsat_model(x)\n",
    "        x = self.proj1(x)\n",
    "        \n",
    "        y = self.bioclim_norm(y)\n",
    "        y = self.bioclim_model(y)\n",
    "        y = self.proj2(y)\n",
    "        \n",
    "        z = self.proj3(self.sentinel_model(z))\n",
    "        \n",
    "        \n",
    "        xyz = torch.cat((x, y, z), dim=1)\n",
    "        out = self.label(xyz)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46bdfb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93c2c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n",
      "100%|██████████| 108M/108M [00:00<00:00, 133MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "\n",
    "model = MultimodalEnsemble(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2bfdd",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eadd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 8e-5\n",
    "num_epochs = 3\n",
    "positive_weigh_factor = 1.0\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519400e",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "The model is trained for 3 epochs using the AdamW optimizer and a cosine annealing learning rate scheduler. The loss function is BCEWithLogitsLoss with a positive weight factor of 1.0 to address class imbalance. The model is saved after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1845b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 3 epochs started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_344/571872013.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  landsat_sample = torch.nan_to_num(torch.load(os.path.join(self.landsat_data_dir, f\"GLC25-PA-train-landsat-time-series_{survey_id}_cube.pt\")))\n",
      "/tmp/ipykernel_344/571872013.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  landsat_sample = torch.nan_to_num(torch.load(os.path.join(self.landsat_data_dir, f\"GLC25-PA-train-landsat-time-series_{survey_id}_cube.pt\")))\n",
      "/tmp/ipykernel_344/571872013.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  landsat_sample = torch.nan_to_num(torch.load(os.path.join(self.landsat_data_dir, f\"GLC25-PA-train-landsat-time-series_{survey_id}_cube.pt\")))\n",
      "/tmp/ipykernel_344/571872013.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  landsat_sample = torch.nan_to_num(torch.load(os.path.join(self.landsat_data_dir, f\"GLC25-PA-train-landsat-time-series_{survey_id}_cube.pt\")))\n",
      "/tmp/ipykernel_344/571872013.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bioclim_sample = torch.nan_to_num(torch.load(os.path.join(self.bioclim_data_dir, f\"GLC25-PA-train-bioclimatic_monthly_{survey_id}_cube.pt\")))\n",
      "/tmp/ipykernel_344/571872013.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bioclim_sample = torch.nan_to_num(torch.load(os.path.join(self.bioclim_data_dir, f\"GLC25-PA-train-bioclimatic_monthly_{survey_id}_cube.pt\")))\n",
      "/tmp/ipykernel_344/571872013.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bioclim_sample = torch.nan_to_num(torch.load(os.path.join(self.bioclim_data_dir, f\"GLC25-PA-train-bioclimatic_monthly_{survey_id}_cube.pt\")))\n",
      "/tmp/ipykernel_344/571872013.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bioclim_sample = torch.nan_to_num(torch.load(os.path.join(self.bioclim_data_dir, f\"GLC25-PA-train-bioclimatic_monthly_{survey_id}_cube.pt\")))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Batch 0/348, Loss: 0.6932763457298279\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data1, data2, data3, targets, _) in enumerate(train_loader):\n",
    "\n",
    "        data1 = data1.to(device)\n",
    "        data2 = data2.to(device)\n",
    "        data3 = data3.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data1, data2, data3)\n",
    "\n",
    "        pos_weight = targets*positive_weigh_factor  \n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 128 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), f\"{epoch}-multimodal-model.pth\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(\"Scheduler:\",scheduler.state_dict())\n",
    "\n",
    "# Save the trained model\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"multimodal-model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e9478",
   "metadata": {},
   "source": [
    "# Generate predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098371f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "print(\"Done\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    surveys = []\n",
    "    predictions_list = []\n",
    "    top_k_indices = None\n",
    "    for batch_idx, (data1, data2, data3, surveyID) in enumerate(test_loader):\n",
    "\n",
    "        data1 = data1.to(device)\n",
    "        data2 = data2.to(device)\n",
    "        data3 = data3.to(device)\n",
    "\n",
    "        outputs = model(data1, data2, data3)\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "        \n",
    "        batch_top_predictions = []\n",
    "        for el in predictions:\n",
    "            answ = np.array(list(np.nonzero(el > 0.18)[0]))\n",
    "            \n",
    "            if len(answ) < 14:\n",
    "                answ = np.array(np.argsort(-el)[:14])\n",
    "            batch_top_predictions.append(answ)\n",
    "        \n",
    "        batch_top_unique = [unique[el] for el in batch_top_predictions]\n",
    "        \n",
    "        predictions_list.extend(batch_top_unique)\n",
    "        \n",
    "        surveys.extend(surveyID.cpu().numpy())\n",
    "\n",
    "    top_k_indices = predictions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0ea59",
   "metadata": {},
   "source": [
    "# Produce CSV file for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde23ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(lambda x: str(int(x)), row)) for row in top_k_indices]\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
